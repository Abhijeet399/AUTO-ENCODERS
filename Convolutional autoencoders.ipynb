{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "#matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\")\n",
    "trX, trY, teX, teY = mnist.train.images, mnist.train.labels, mnist.test.images, mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network Parameters\n",
    "h_in, w_in = 28, 28 # Image size height and width\n",
    "k = 3 # Kernel size\n",
    "p = 2 # pool\n",
    "s = 2 # Strides in maxpool\n",
    "filters = {1:32,2:32,3:16}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_fn=tf.nn.relu\n",
    "# Change in dimensions of image after each MaxPool\n",
    "h_l2, w_l2 = int(np.ceil(float(h_in)/float(s))) , int(np.ceil(float(w_in)/float(s))) \n",
    "# Height and width: second encoder/decoder layer\n",
    "h_l3, w_l3 = int(np.ceil(float(h_l2)/float(s))) , int(np.ceil(float(w_l2)/float(s)))\n",
    "# Height and width: third encoder/decoder layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_noisy = tf.placeholder(tf.float32, (None, h_in, w_in, 1), name='inputs')\n",
    "X = tf.placeholder(tf.float32, (None, h_in, w_in, 1), name='targets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Encoder\n",
    "conv1 = tf.layers.conv2d(X_noisy, filters[1], (k,k), padding='same',\n",
    "activation=activation_fn)\n",
    "# Output size h_in x w_in x filters[1]\n",
    "maxpool1 = tf.layers.max_pooling2d(conv1, (p,p), (s,s), padding='same')\n",
    "# Output size h_l2 x w_l2 x filters[1]\n",
    "conv2 = tf.layers.conv2d(maxpool1, filters[2], (k,k), padding='same',\n",
    "activation=activation_fn)\n",
    "# Output size h_l2 x w_l2 x filters[2]\n",
    "maxpool2 = tf.layers.max_pooling2d(conv2,(p,p), (s,s), padding='same')\n",
    "# Output size h_l3 x w_l3 x filters[2]\n",
    "conv3 = tf.layers.conv2d(maxpool2,filters[3], (k,k), padding='same',\n",
    "activation=activation_fn)\n",
    "# Output size h_l3 x w_l3 x filters[3]\n",
    "encoded = tf.layers.max_pooling2d(conv3, (p,p), (s,s), padding='same')\n",
    "# Output size h_l3/s x w_l3/s x filters[3] Now 4x4x16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Decoder\n",
    "upsample1 = tf.image.resize_nearest_neighbor(encoded, (h_l3,w_l3))\n",
    "# Output size h_l3 x w_l3 x filters[3]\n",
    "conv4 = tf.layers.conv2d(upsample1, filters[3], (k,k), padding='same',\n",
    "activation=activation_fn)\n",
    "# Output size h_l3 x w_l3 x filters[3]\n",
    "upsample2 = tf.image.resize_nearest_neighbor(conv4, (h_l2,w_l2))\n",
    "# Output size h_l2 x w_l2 x filters[3]\n",
    "conv5 = tf.layers.conv2d(upsample2, filters[2], (k,k), padding='same',\n",
    "activation=activation_fn)\n",
    "# Output size h_l2 x w_l2 x filters[2]\n",
    "upsample3 = tf.image.resize_nearest_neighbor(conv5, (h_in,w_in))\n",
    "# Output size h_in x w_in x filters[2]\n",
    "conv6 = tf.layers.conv2d(upsample3, filters[1], (k,k), padding='same',\n",
    "activation=activation_fn)\n",
    "# Output size h_in x w_in x filters[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = tf.layers.conv2d(conv6, 1, (k,k) , padding='same',\n",
    "activation=None)\n",
    "# Output size h_in x w_in x 1\n",
    "decoded = tf.nn.sigmoid(logits, name='decoded')\n",
    "loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=X, logits=logits)\n",
    "cost = tf.reduce_mean(loss)\n",
    "opt = tf.train.AdamOptimizer(0.001).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
